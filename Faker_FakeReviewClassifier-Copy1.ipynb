{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CSCE 670 :: Information Storage and Retrieval - Final Project Report\n",
    "\n",
    "<h1><center>Amazon Fake Reviews Classifier and Analysis</center></h1>\n",
    "<h4><center> Josiah Coad, Savinay Narendra, Sheelabhadra Dey, Chaiwei Chang, Kevin Chang</center></h4>\n",
    "Github: [Click Me](https://github.com/josiahcoad/Faker)<br>\n",
    "Data: Please refer to library folder in the repository. (Source: Amazon)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  It has become a common practice for online reviews to have a major impact on the decision of the potential customers of that product. Positive reviews can result in significant financial gains. This gives a strong incentive for fraud reviews, also commonly called opinion scamming. Opinion scamming includes fake blogs, reviews, deceptive advertising and more. Our research is accordingly focusing on product reviews based on the Amazon dataset both from University of Illinois at Chicago[1] and Professor Caverlee’s lab at Texas A&M University. Reports indicated 2-6% reviews on average are fake with up to 20% on sites such as Yelp. This leads to an unrealistic representation of places and products on the internet. Additionally, there are some fake review cases in the news for example [6].\n",
    "\n",
    "  Based on existing machine learnign techniques, we applied unsupervised clustering and observe that whether the spam/fake reviewers can be clustered together. In order to enhance the performance of learning process, we preprocessed the data to focus on suspicious group or individual because we believe that the some obivious features are similar within these groups.\n",
    "  \n",
    "  The key difficulty in determining fake reviews is that it is extremely hard for humans to identify fake reviews. In one related work, it was said to take a team of industry experts eight weeks to develop a labeled data set. We believe that a machine can do better at identifying the fake reviews by extracting the implicit information or behavior feature inside the reviews efficiently.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Initialization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 99117\n",
      "Number of reviewers: 4743\n",
      "Number of reviewers with 3+ reviews rated 1 or 5 star: 3268\n",
      "('A2R1SS382YW679', [])\n",
      "\n",
      "('A135L0KYJC3K4H', [])\n",
      "\n",
      "('A1NGEEN1F7FVMK', [])\n",
      "\n",
      "('A3L7Z3ZXGIMWD3', [])\n",
      "Number of groups:  261\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from collections import defaultdict\n",
    "\n",
    "def parserJSON(path, numLines=None):\n",
    "  numLines = numLines or len(open(path).read().split(\"\\n\")) - 1\n",
    "  with open(path) as txt:\n",
    "    reviews = [eval(next(txt)) for x in range(numLines)]\n",
    "  print(\"Number of reviews:\", len(reviews))\n",
    "  return reviews\n",
    "\n",
    "\n",
    "def get_reviewers(reviews):\n",
    "   reviewers = {}\n",
    "   for review in reviews:\n",
    "      reviewerId = review[\"memberId\"]\n",
    "      if reviewerId not in reviewers:\n",
    "         reviewers[reviewerId] = [review]\n",
    "      else:\n",
    "         reviewers[reviewerId].append(review)\n",
    "   print(\"Number of reviewers:\", len(reviewers))\n",
    "   return reviewers\n",
    "\n",
    "def remove_lessthan3(reviewers_reviews):\n",
    "   final = {}\n",
    "   for reviewer, reviews in reviewers_reviews.items():\n",
    "      reviews = list(filter(lambda review: review[\"Rate\"] == 1 or review[\"Rate\"] == 5, reviews))\n",
    "      if len(reviews) >= 3:\n",
    "            final[reviewer] = sorted(reviews, key=lambda review: review[\"productId\"])\n",
    "   print(\"Number of reviewers with 3+ reviews rated 1 or 5 star:\", len(final))\n",
    "   return final\n",
    "\n",
    "def get_products(reviews):\n",
    "   products = {}\n",
    "   for review in reviews:\n",
    "      productId = review[\"productId\"]\n",
    "      if productId not in products:\n",
    "         products[productId] = [review]\n",
    "      else:\n",
    "         products[productId].append(review)\n",
    "   return products\n",
    "\n",
    "def normalizedVector(vector):\n",
    "    total = 0\n",
    "    for key in vector:\n",
    "        total += vector[key] ** 2\n",
    "    total = total ** 0.5\n",
    "    for key in vector:\n",
    "        vector[key] /= total\n",
    "    return vector\n",
    "\n",
    "\n",
    "# from modules.amazon_parser import *\n",
    "reviewers_products = []\n",
    "\n",
    "# get a list of dictionary items which represent each review object (including metadata like product id and user id) \n",
    "reviews = parserJSON('./library/amazon-review-data.json')\n",
    "# get a list of tuples with user as first entry and a list of the review objects their part of as the second\n",
    "reviewers_reviews_dict = get_reviewers(reviews)\n",
    "reviewers_reviews = reviewers_reviews_dict\n",
    "# remove all reviewers who reviewed less than 3 products with ratings other than 1 or 5\n",
    "reviewers_reviews = remove_lessthan3(reviewers_reviews)\n",
    "\n",
    "# create a new list of tuples... with first entry being the reviewer \n",
    "# and second being a list of the product ids reviewed\n",
    "for reviewer, reviews in reviewers_reviews.items():\n",
    "   reviewers_products.append( (reviewer, [review[\"productId\"] for review in reviews]) )\n",
    "\n",
    "# get a sorted list of reviews that a user left for products which match 'productIds'\n",
    "def get_product_reviews(productIds, userId):\n",
    "   return [review for review in reviewers_reviews_dict[userId] if review[\"productId\"] in productIds]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 Group Indicator\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A2R1SS382YW679', [])\n",
      "\n",
      "('A135L0KYJC3K4H', [])\n",
      "\n",
      "('A1NGEEN1F7FVMK', [])\n",
      "\n",
      "('A3L7Z3ZXGIMWD3', [])\n",
      "Number of groups:  261\n",
      "Number of reviews: 99117\n"
     ]
    }
   ],
   "source": [
    "groups = []\n",
    "for i in range(len(reviewers_products)-1):\n",
    "   ref_user = reviewers_products[i]\n",
    "   newgroup = [ref_user]\n",
    "   for j in range(i+1, len(reviewers_products)):\n",
    "      compare_user = reviewers_products[j]\n",
    "      shared_products = set(ref_user[1]).intersection(set(compare_user[1]))\n",
    "      if len(shared_products) >= 3:\n",
    "         newgroup.append(compare_user)\n",
    "   if len(newgroup) >= 2:\n",
    "      group_products = sorted(list(set(ref_user[1]).intersection(*[set(user[1]) for user in newgroup])))\n",
    "      newgroup = [( user[0], get_product_reviews(group_products, user[0]) ) for user in newgroup]\n",
    "      groups.append(newgroup)\n",
    "print(*groups[0], sep=\"\\n\\n\")\n",
    "print(\"Number of groups: \", len(groups))\n",
    "\n",
    "import math, re, string\n",
    "from collections import defaultdict\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def purify(s):\n",
    "   s = s.translate(None, string.punctuation)\n",
    "   s = re.sub('(\\s+)(a|an|and|but|the)(\\s+)', ' ', s)\n",
    "   s = [ps.stem(word.lower()) for word in re.split('\\W+', s)]\n",
    "   # print(s)\n",
    "   return s\n",
    "\n",
    "\n",
    "ps = PorterStemmer()\n",
    "def cosine_sim(string1, string2):\n",
    "   count1 = defaultdict(int)\n",
    "   count2 = defaultdict(int)\n",
    "   for word in purify(string1):\n",
    "      count1[ps.stem(word.lower())] += 1\n",
    "   for word in purify(string2):\n",
    "      count2[ps.stem(word.lower())] += 1\n",
    "   dot_product = sum(count1.get(key, 0)*count2.get(key, 0) for key in count1)\n",
    "   magnitude = math.sqrt(sum([int(val)**2 for val in count1.values()])) * math.sqrt(sum([int(val)**2 for val in count2.values()]))\n",
    "   return dot_product/magnitude if magnitude else 0\n",
    "\n",
    "from numpy import mean as avg\n",
    "\n",
    "review_objects = parserJSON('./library/amazon-review-data.json')\n",
    "\n",
    "products_dict  = get_products(review_objects) # create a dict with product ID as the key and a list of the product's reviews as the value\n",
    "\n",
    "\n",
    "products_dict = get_products(review_objects) # create a dict with product ID as the key and a list of the product's reviews as the value\n",
    "\n",
    "\n",
    "MAX_USERS = 5 # found previously\n",
    "MAX_PRODS = 7 # found previously\n",
    "\n",
    "\n",
    "with open(\"./library/groups.txt\") as f:\n",
    "   groups = eval(f.read())\n",
    "\n",
    "# takes a dictionary of groups which are organized by groupID as the key and a list of tuples as the value\n",
    "# return a list of groups where each group is structured as: [(product, [reviews]), (product, [reviews])]\n",
    "def organize_by_product(groups_dict):\n",
    "   group_list = []\n",
    "   for groupId, group in groups_dict.items():\n",
    "      reviews = []\n",
    "      for user, user_reviews in group:\n",
    "         reviews.extend(user_reviews)\n",
    "      products_reviews = defaultdict(list)\n",
    "      for review in reviews:\n",
    "         products_reviews[review[\"productId\"]].append(review)\n",
    "      group_list.append( products_reviews.items() )\n",
    "   return group_list\n",
    "\n",
    "groups_by_products = organize_by_product(groups)\n",
    "\n",
    "# takes a dictionary of groups which are organized by groupID as the key and a list of tuples as the value\n",
    "# return a list of groups where each group is structured as: [(reviewer, [reviews]), (reviewer, [reviews])]\n",
    "def organize_by_user(groups_dict):\n",
    "   return [groups_dict[key] for key in groups_dict]\n",
    "\n",
    "groups_by_reviewers = organize_by_user(groups)\n",
    "\n",
    "def get_avg(Name):\n",
    "    if(len(products_dict[Name])>0):\n",
    "        count = 0\n",
    "        sum = 0\n",
    "        for i in range(len(products_dict[Name])):\n",
    "            sum+= products_dict[Name][i][\"Rate\"]\n",
    "            count+=1\n",
    "        return float(sum/count)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Group Deviation (GD)\n",
    "def GD(group):\n",
    "    Deviation = []\n",
    "    handle = set()\n",
    "    for i in range(len(group)):\n",
    "        cur_user = group[i]\n",
    "        for item in cur_user[1]:\n",
    "            if(item[\"productId\"] not in handle):\n",
    "                handle.add(item[\"productId\"])\n",
    "                if(item[\"Rate\"]==5):\n",
    "                    Deviation.append(abs(5-get_avg(item[\"productId\"]))/4)\n",
    "                elif(cur_user[1][1][\"Rate\"]==1):\n",
    "                    Deviation.append(abs(get_avg(item[\"productId\"])-1)/4)\n",
    "    return max(Deviation)\n",
    "\n",
    "# Group Member Content Similarity\n",
    "def GMCS(group):\n",
    "  MCS = []\n",
    "  count = []\n",
    "  for i in range(len(group)):\n",
    "    cur_user = group[i]\n",
    "    MCS.append(0)\n",
    "    count.append(0)\n",
    "    for x in range(len(cur_user[1])-1):#each review\n",
    "      for y in range(x+1,len(cur_user[1])):\n",
    "        MCS[i]+=cosine_sim(cur_user[1][x][\"reviewText\"], cur_user[1][y][\"reviewText\"])    \n",
    "        count[i]+=1 \n",
    "    MCS[i]/=count[i]\n",
    "  Sum = 0\n",
    "  for indi in MCS:\n",
    "    Sum+=indi\n",
    "  return float(Sum)/len(group)\n",
    "\n",
    "# Group Size (GS) (number of users in group)\n",
    "def GS(group_by_users):\n",
    "    return float(len(group_by_users)) / MAX_USERS\n",
    "\n",
    "# Group Size Ratio (GSR) (returns 1 if each product in the group were only reviewed by the group members)\n",
    "def GSR(group_by_products):\n",
    "  return avg ( [gsr(product, reviews) for product, reviews in group_by_products] )\n",
    "\n",
    "def gsr(product, reviews):\n",
    "  return float(len(reviews)) / len(products_dict[product])\n",
    "# ------------------------\n",
    "\n",
    "def GTW(group):\n",
    "   return max([prod_TW(reviews) for product, reviews in group])\n",
    "\n",
    "def prod_TW(reviews):\n",
    "   GTW_MAXTIME = 345600 # number of seconds in 4 days\n",
    "   timestamps = [float(review[\"Date\"]) for review in reviews]\n",
    "   _range = max(timestamps)-min(timestamps)\n",
    "   return 1-_range/GTW_MAXTIME if _range < GTW_MAXTIME else 0\n",
    "\n",
    "def GCS(group):\n",
    "   return max([CS(reviews) for product, reviews in group])\n",
    "\n",
    "def CS(reviews):\n",
    "   texts = [review[\"reviewText\"] for review in reviews]\n",
    "   return avg([cosine_sim(review1, review2) for review1 in texts for review2 in texts])\n",
    "\n",
    "def GETF(group):\n",
    "   return max([GTF(product, reviews) for product, reviews in group])\n",
    "\n",
    "def GTF(product, reviews):\n",
    "   GTF_MAXTIME = 15552000 # seconds in 6 months\n",
    "   earliest_product_review = min([float(review[\"Date\"]) for review in products_dict[product]])\n",
    "   latest_group_review = max([float(review[\"Date\"]) for review in reviews])\n",
    "   _range = latest_group_review-earliest_product_review\n",
    "   return 1-_range/GTF_MAXTIME if _range < GTF_MAXTIME else 0\n",
    "\n",
    "# Group Support Count (GSUP) (number of products in group)\n",
    "def GSUP(group):\n",
    "  return float(len(group)) / MAX_PRODS\n",
    "\n",
    "# Sum Scores\n",
    "def scores(gbp, gbr):\n",
    "   return [GCS(gbp), GTW(gbp), GETF(gbp), GSUP(gbp), GS(gbr), GSR(gbp), GD(gbr), GMCS(gbr)]\n",
    "\n",
    "\n",
    "def get_all_scores():\n",
    "  all_scores = []\n",
    "  for i in range(len(groups_by_reviewers)):\n",
    "     all_scores.append(scores(groups_by_products[i], groups_by_reviewers[i]))\n",
    "  return all_scores\n",
    "\n",
    "# scores = [( i, sum(score) ) for i, score in enumerate(get_all_scores())]\n",
    "# fakest_indexes = sorted(scores, lambda k: k[1], reverse=True)\n",
    "# for top in fakest_indexes[:5]:\n",
    "#   fakest_users = [reviewer for reviewer, review in groups_by_reviewers[fakest_index]]\n",
    "#   print(fakest_users)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### 2.2 Individual Indicator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "import math as math\n",
    "from random import randint\n",
    "class som:\n",
    "    def __init__(self, input,maxIterations=10,sigmaInitial = 4,somCol=3, somRow=3):\n",
    "\t\tself.somCol = somCol\n",
    "\t\tself.somRow = somRow\n",
    "                self.input  = input\n",
    "                self.maxIterations = maxIterations;\n",
    "                self.sigmaInitial = sigmaInitial\n",
    "    \n",
    " \n",
    "    def trainmodel(self):\n",
    "        input = self.input\n",
    "       \n",
    "        somCol = self.somCol\n",
    "        somRow = self.somRow\n",
    "        inputvectorlen = len(input[0,:])\n",
    "        inputsSize = len(input[:,0])\n",
    "        #initialise neurons layer.\n",
    "        somMap = numpy.zeros(shape=(somCol,somRow,inputvectorlen))\n",
    "        #print somMap\n",
    "\n",
    "        #Max number of iterations\n",
    "        maxIterations = self.maxIterations\n",
    "\n",
    "        # Initial effective width\n",
    "        sigmaInitial = self.sigmaInitial\n",
    "\n",
    "        # Time constant for sigma\n",
    "        t1 = maxIterations / numpy.log(sigmaInitial)\n",
    "\n",
    "        #Initialise matrix to store eucledian distances.\n",
    "        #euclideanD = numpy.zeros(shape =(somRow, somCol))\n",
    "       \n",
    "        # Initialize 10x10 matrix to store neighbourhood functions\n",
    "        # of each neurons on the map\n",
    "        neighbourhoodFunctionVal = numpy.zeros(shape =(somRow, somCol));\n",
    "\n",
    "        # initial learning rate\n",
    "        learningRateInitial = 0.1;\n",
    "\n",
    "        #time constant for eta\n",
    "        t2 = maxIterations;\n",
    "        #Assign random weight vectors for all the neurons\n",
    "        for num in range (0,(somRow)):\n",
    "            for iter in range (0,(somCol)):\n",
    "                #Squeezed the matrix into an ndarray.\n",
    "                somMap[num,iter,:] = numpy.squeeze(numpy.random.rand(inputvectorlen,1))\n",
    "                    \n",
    "#         print \"Again #printing the som with randomly initialised weight vectors\"\n",
    "#         print somMap\n",
    "\n",
    "        count = 1;\n",
    "        while(count < maxIterations):\n",
    "            \n",
    "            sigma = sigmaInitial * numpy.exp(-count/t1)\n",
    "            variance = pow(sigma,2) \t\n",
    "            eta = learningRateInitial * numpy.exp(-count/t2)\n",
    "    \n",
    "            #Prevent eta from falling below 0.01\n",
    "            if (eta < 0.01):\n",
    "                eta = 0.01\n",
    "            #Randomly select a weight vector from the input weight vectors.\n",
    "            inputIndex = randint(0,inputsSize-1)\n",
    "            selectedWeightVector = input[inputIndex,:]\n",
    "          \n",
    "            #Select the winning neuron which has the weight vector closest to that of selected input weight vector.\n",
    "            #Find the indices of minimum eucledian distance element.\n",
    "            mineuclideanD=numpy.linalg.norm(selectedWeightVector-somMap[0,0,:])\n",
    "            minr=0\n",
    "            minc=0\n",
    "            for num in range (0,somRow):\n",
    "                for iter in range (0,somCol):\n",
    "                    \n",
    "                    temp  = numpy.linalg.norm(selectedWeightVector-somMap[num,iter,:])\n",
    "                    \n",
    "                    if(temp <=mineuclideanD):\n",
    "                        minr=num\n",
    "                        minc=iter\n",
    "                        mineuclideanD=temp\n",
    "            #print euclideanD\n",
    "                   \n",
    "            #print 'indices are',minr,minc\n",
    "        \n",
    "            #compute the neighbourhood function for all the neurons\n",
    "            #For the winning noe\n",
    "            for r in range (0,somRow):\n",
    "                for c in range (0,somCol):\n",
    "                    if (r == minr & c == minc):  \n",
    "                        neighbourhoodFunctionVal[r, c] = 1;\n",
    "                        continue;\n",
    "                    else:\n",
    "                        distance = (minr - r)^2 + (minc - c)^2;\n",
    "                        neighbourhoodFunctionVal[r, c] = numpy.exp(-distance/(2*variance));\n",
    "            \n",
    "            #print 'neighbourhood functions are',neighbourhoodFunctionVal\n",
    "            #Update weights \n",
    "\n",
    "            for r in range (0,somRow):\n",
    "                for c in range (0,somCol):\n",
    "                    oldWeightVector = somMap[r, c,:]\n",
    "                    somMap[r, c,:]     = oldWeightVector + eta*neighbourhoodFunctionVal[r, c]*(selectedWeightVector - oldWeightVector)\n",
    "   \n",
    "            #Increment the counter\n",
    "            count +=1\n",
    "        \n",
    "        #Return updated map of neurons.\n",
    "        return somMap\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model is [[[ 0.86873737  0.722772    0.37563978  0.60210187  0.83515825  0.73670491\n",
      "    0.11304375  0.36711602]\n",
      "  [ 0.86879263  0.80270152  0.69239661  0.89949096  0.75284733  0.71704691\n",
      "    0.75496031  0.77311934]\n",
      "  [ 0.87523371  0.52073934  0.70366966  0.20782134  0.42443584  0.43883043\n",
      "    0.46791777  0.73526197]\n",
      "  [ 0.39466976  0.55776331  0.61962557  0.7222089   0.56766668  0.14485464\n",
      "    0.36985992  0.59708854]\n",
      "  [ 0.36499381  0.60159268  0.68025203  0.26062214  0.61416041  0.36399045\n",
      "    0.07610384  0.51782515]\n",
      "  [ 0.74068678  0.64419985  0.85684241  0.82316189  0.38558285  0.2470232\n",
      "    0.35141184  0.30793878]\n",
      "  [ 0.81968896  0.55032513  0.9085003   0.49987986  0.63856564  0.21034179\n",
      "    0.2521369   0.58636993]\n",
      "  [ 0.69955258  0.93980972  0.98241344  0.84026044  0.39584135  0.31046762\n",
      "    0.07363662  0.38181184]\n",
      "  [ 0.760588    0.85069933  0.77104002  0.67463311  0.38024     0.23136249\n",
      "    0.13964104  0.2902743 ]\n",
      "  [ 0.66962262  0.8243615   0.95790111  0.74175401  0.43488037  0.46570014\n",
      "    0.25537785  0.38471626]]\n",
      "\n",
      " [[ 0.7077743   0.81929456  0.97022829  0.82055462  0.57625252  0.33604813\n",
      "    0.29558879  0.28574689]\n",
      "  [ 0.50788751  0.9226863   0.89521195  0.59538661  0.43827043  0.47330411\n",
      "    0.32931626  0.6041276 ]\n",
      "  [ 0.66181559  0.88110576  0.86482413  0.69032873  0.45998407  0.43563181\n",
      "    0.1564383   0.35349096]\n",
      "  [ 0.72281356  0.75840409  0.8095328   0.72925244  0.50104102  0.31465652\n",
      "    0.23377192  0.35618637]\n",
      "  [ 0.43367099  0.88896808  0.77343384  0.8584433   0.50605167  0.37889178\n",
      "    0.31546463  0.29480499]\n",
      "  [ 0.73734459  0.79311905  0.86095975  0.51783849  0.54200889  0.4966377\n",
      "    0.32401035  0.26965767]\n",
      "  [ 0.64178006  0.93128081  0.91859173  0.81254444  0.30974917  0.30086998\n",
      "    0.23894229  0.42618417]\n",
      "  [ 0.65972832  0.83778945  0.85101587  0.85752257  0.36172202  0.23916993\n",
      "    0.1069917   0.36258594]\n",
      "  [ 0.68045882  0.9464855   0.99432104  0.83061285  0.41024384  0.31962406\n",
      "    0.08783543  0.37289347]\n",
      "  [ 0.77981437  0.47797786  0.95741275  0.75320859  0.29124948  0.46594112\n",
      "    0.53069946  0.18876894]]\n",
      "\n",
      " [[ 0.54530985  0.64398698  0.85486647  0.60347019  0.61529144  0.62317043\n",
      "    0.30992203  0.44690576]\n",
      "  [ 0.78799268  0.60883613  0.85159546  0.84485794  0.33046971  0.20735818\n",
      "    0.18714116  0.30221005]\n",
      "  [ 0.75277463  0.85095695  0.90548516  0.62190967  0.48871045  0.46224656\n",
      "    0.12139656  0.29579785]\n",
      "  [ 0.78463381  0.94506281  0.85558539  0.72366645  0.34934925  0.36889898\n",
      "    0.11837204  0.41842648]\n",
      "  [ 0.82980199  0.4519756   0.51657086  0.44703401  0.57491366  0.54760591\n",
      "    0.56081415  0.64585327]\n",
      "  [ 0.69228995  0.92805108  0.94089997  0.83917967  0.40534735  0.31512766\n",
      "    0.08799655  0.37286555]\n",
      "  [ 0.7194996   0.7592595   0.92250134  0.69451361  0.39110148  0.40609004\n",
      "    0.16419571  0.33406923]\n",
      "  [ 0.76850138  0.78292435  0.87494098  0.66255057  0.49239529  0.34598473\n",
      "    0.29990254  0.46705268]\n",
      "  [ 0.64895827  0.59990381  0.94687142  0.73696127  0.55106981  0.27422549\n",
      "    0.19298003  0.31755396]\n",
      "  [ 0.77312681  0.81513463  0.92498622  0.50069787  0.25417303  0.36532855\n",
      "    0.39745691  0.63324731]]\n",
      "\n",
      " [[ 0.65302485  0.86701667  0.85672071  0.7620356   0.44345667  0.37794594\n",
      "    0.20813933  0.35368075]\n",
      "  [ 0.7505606   0.76658657  0.83216137  0.67867546  0.50670945  0.31349121\n",
      "    0.15041457  0.55896858]\n",
      "  [ 0.80171616  0.78417365  0.77861648  0.68971875  0.4093956   0.29692501\n",
      "    0.38592369  0.55171796]\n",
      "  [ 0.83596627  0.67481479  0.69094948  0.78621779  0.25007465  0.33367403\n",
      "    0.31933107  0.58272497]\n",
      "  [ 0.5287315   0.70584264  0.61788058  0.51219357  0.24552512  0.36156654\n",
      "    0.07319912  0.37535984]\n",
      "  [ 0.63848434  0.91400928  0.96329651  0.70796901  0.35672902  0.31091043\n",
      "    0.2405399   0.32496602]\n",
      "  [ 0.65671802  0.97242393  0.98873069  0.85182421  0.43084701  0.3148642\n",
      "    0.07494899  0.3734023 ]\n",
      "  [ 0.60836395  0.52215945  0.55513178  0.59012799  0.31375118  0.26065041\n",
      "    0.05202302  0.60301067]\n",
      "  [ 0.78500074  0.72663006  0.86763074  0.68090597  0.30281866  0.19140928\n",
      "    0.17450501  0.42304247]\n",
      "  [ 0.6010185   0.81849356  0.44929468  0.35069686  0.29287322  0.53620404\n",
      "    0.40072648  0.3167293 ]]\n",
      "\n",
      " [[ 0.67401889  0.91875194  0.75983947  0.64064982  0.35327657  0.36876439\n",
      "    0.31664436  0.55564938]\n",
      "  [ 0.77823142  0.94503668  0.9492159   0.67061399  0.47536747  0.36483018\n",
      "    0.18058429  0.37741202]\n",
      "  [ 0.66341273  0.54995006  0.95361301  0.61582935  0.2811858   0.25938373\n",
      "    0.08633258  0.33990946]\n",
      "  [ 0.64581487  0.69222173  0.88824901  0.67966496  0.26685171  0.26838268\n",
      "    0.21609266  0.53252843]\n",
      "  [ 0.83853691  0.58884832  0.66743077  0.77249371  0.32465107  0.19920122\n",
      "    0.47540831  0.38318655]\n",
      "  [ 0.47515259  0.59454769  0.94507818  0.56184032  0.35266256  0.44810606\n",
      "    0.05301123  0.44018603]\n",
      "  [ 0.76121809  0.71289887  0.91804849  0.81427651  0.61628922  0.52055843\n",
      "    0.49292547  0.26641648]\n",
      "  [ 0.79219883  0.9032216   0.93950934  0.50201054  0.35852646  0.29082658\n",
      "    0.15521489  0.36462306]\n",
      "  [ 0.67480845  0.68883212  0.95366025  0.80801065  0.4578997   0.45884866\n",
      "    0.19397343  0.39827966]\n",
      "  [ 0.78891318  0.7807259   0.71413145  0.69443633  0.47520474  0.44497261\n",
      "    0.06998048  0.55266588]]\n",
      "\n",
      " [[ 0.73649287  1.03630129  1.09113945  0.81777607  0.36730403  0.3527157\n",
      "    0.00471259  0.36724086]\n",
      "  [ 0.75626604  0.94469354  0.97745364  0.72793732  0.40764001  0.40532729\n",
      "    0.06007987  0.40899315]\n",
      "  [ 0.85667148  1.36249898  1.20412985  0.62351863  0.20999009  0.40268181\n",
      "   -0.31765463  0.2431439 ]\n",
      "  [ 0.82083281  1.22623078  1.25266442  0.7116025   0.27286041  0.4436594\n",
      "    0.00643763  0.28597164]\n",
      "  [ 0.8097182   0.54231414  0.45122985  0.45793942  0.22600877  0.56943648\n",
      "    0.24706718  0.58064977]\n",
      "  [ 0.39508397  0.7872708   0.38470664  0.42730537  0.3684913   0.55995582\n",
      "    0.36122803  0.30330988]\n",
      "  [ 0.74196975  0.59251736  0.89132731  0.80689076  0.49547609  0.42822263\n",
      "    0.47653475  0.26082662]\n",
      "  [ 0.81449211  0.51351753  0.7926131   0.81567642  0.50543772  0.51895167\n",
      "    0.30315485  0.36319831]\n",
      "  [ 0.79394772  0.87197812  0.83774648  0.58046642  0.57860037  0.21073223\n",
      "    0.09843974  0.51118369]\n",
      "  [ 0.56242202  0.58415067  0.63382783  0.66224558  0.48602891  0.45024497\n",
      "    0.1099847   0.39598649]]\n",
      "\n",
      " [[ 0.73734196  0.93020733  0.98961584  0.76889507  0.4017811   0.347543\n",
      "    0.08652387  0.38714093]\n",
      "  [ 0.77598878  1.00826455  1.04975686  0.86717181  0.40566137  0.27251539\n",
      "    0.09695686  0.30578286]\n",
      "  [ 0.84496783  0.98951782  1.09130132  0.91329501  0.41258776  0.38171975\n",
      "   -0.0193586   0.39526953]\n",
      "  [ 1.07130201  1.27564992  1.2510928   0.91631353  0.34952239  0.61784402\n",
      "   -0.34426451  0.27742626]\n",
      "  [ 0.35355845  0.86682436  0.36843277  0.8222606   0.2869402   0.33587242\n",
      "    0.48357753  0.70718049]\n",
      "  [ 0.62848777  0.79090691  0.84063738  0.82391101  0.71169459  0.31837171\n",
      "    0.16728967  0.35870711]\n",
      "  [ 0.68477608  0.62856136  0.64536854  0.75470937  0.42620218  0.36782209\n",
      "    0.12272861  0.4379852 ]\n",
      "  [ 0.81197454  0.85213395  0.95704529  0.80242611  0.24918077  0.1297259\n",
      "    0.47645315  0.57171959]\n",
      "  [ 0.39826109  0.4391768   0.58868251  0.87863398  0.35041634  0.14725299\n",
      "    0.2627163   0.40285434]\n",
      "  [ 0.6704256   0.95506898  0.95050778  0.85887569  0.41358948  0.32024286\n",
      "    0.08293179  0.37003046]]\n",
      "\n",
      " [[ 0.7974139   1.16603558  1.09642792  0.70689459  0.24420075  0.42166077\n",
      "    0.07955835  0.34546805]\n",
      "  [ 0.86867086  1.08423559  1.14710194  0.78389516  0.31743987  0.21139944\n",
      "    0.04209478  0.31280337]\n",
      "  [ 0.71996908  0.98806975  1.0334479   0.8494425   0.41284425  0.22873591\n",
      "    0.10976924  0.35130364]\n",
      "  [ 0.74566119  0.93289471  0.98048342  0.71046805  0.39314082  0.40747177\n",
      "    0.05055279  0.41749265]\n",
      "  [ 0.51303728  0.54093678  0.66368937  0.49652898  0.66992606  0.61977112\n",
      "    0.3429718   0.61490109]\n",
      "  [ 0.75659938  0.40922837  0.939898    0.42112655  0.28500415  0.33902114\n",
      "    0.31396263  0.40773593]\n",
      "  [ 0.65147308  0.68920584  0.73563762  0.62399825  0.50785496  0.31319945\n",
      "    0.13808707  0.68173472]\n",
      "  [ 0.76541549  0.54715733  0.85098454  0.69517751  0.5885861   0.24766046\n",
      "    0.42434185  0.68779146]\n",
      "  [ 0.79070229  0.68398169  0.65382049  0.75962037  0.62077115  0.19393086\n",
      "    0.40443861  0.5239399 ]\n",
      "  [ 0.71306335  0.8472678   0.92664685  0.76698976  0.41860674  0.44171714\n",
      "    0.08450059  0.35472288]]\n",
      "\n",
      " [[ 0.75465832  1.02854363  1.02089378  0.84722351  0.35929796  0.28489437\n",
      "    0.01693085  0.36631963]\n",
      "  [ 0.90087166  1.01160234  1.17515562  0.7855719   0.46997667  0.33812081\n",
      "   -0.20007602  0.40184674]\n",
      "  [ 0.74404785  0.94614551  0.98382203  0.76182036  0.4099904   0.35063732\n",
      "    0.07988446  0.39111884]\n",
      "  [ 0.74076505  1.04159643  1.10103031  0.72460625  0.40201881  0.38733227\n",
      "    0.02459447  0.45029769]\n",
      "  [ 0.47184366  0.38421668  0.48046746  0.31249483  0.50489423  0.4331\n",
      "    0.35939628  0.55766153]\n",
      "  [ 0.81499138  0.61395161  0.83196909  0.59212734  0.55680791  0.44466438\n",
      "    0.3706036   0.71691688]\n",
      "  [ 0.69608161  0.4184827   0.43194023  0.37279038  0.60122731  0.47503036\n",
      "    0.05418232  0.31140647]\n",
      "  [ 0.32445183  0.39200873  0.47414145  0.82062478  0.74471831  0.57655986\n",
      "    0.46684618  0.5044992 ]\n",
      "  [ 0.795211    0.41620634  0.92253529  0.68597568  0.34313898  0.68200125\n",
      "    0.36405565  0.28021542]\n",
      "  [ 0.77625992  0.43974933  0.48399311  0.67672202  0.32863997  0.3914588\n",
      "    0.09720603  0.25536628]]\n",
      "\n",
      " [[ 0.66317574  0.95670227  0.9693792   0.84631701  0.40567739  0.31264161\n",
      "    0.07174081  0.36924906]\n",
      "  [ 0.46883889  0.57200281  0.73464645  0.48022449  0.46485591  0.44428657\n",
      "    0.43306523  0.46486585]\n",
      "  [ 0.81584668  0.62189205  0.62404831  0.69525414  0.61837467  0.16919869\n",
      "    0.27286387  0.3163621 ]\n",
      "  [ 0.46797907  0.74666079  0.51764216  0.64042471  0.25880183  0.5451821\n",
      "    0.34378264  0.36326597]\n",
      "  [ 0.80242384  1.01606173  1.03808088  0.72507427  0.38682715  0.43015375\n",
      "    0.041841    0.37798802]\n",
      "  [ 0.73844039  0.93329848  0.98506673  0.71190912  0.41518816  0.404866\n",
      "    0.0683943   0.42423182]\n",
      "  [ 0.78062286  1.25846455  1.3539448   0.72953759  0.15697162  0.52972119\n",
      "   -0.09589682  0.28271479]\n",
      "  [ 0.84109577  1.19419455  1.27051221  0.64820709  0.44935346  0.28339788\n",
      "   -0.00188089  0.30571896]\n",
      "  [ 0.82021158  0.74486352  0.72430679  0.48215597  0.54843376  0.28110671\n",
      "    0.38373693  0.43147194]\n",
      "  [ 0.47623828  0.5812287   0.5674994   0.72642432  0.23408403  0.47754694\n",
      "    0.28745091  0.46593204]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "with open(\"./library/groups.txt\") as f:\n",
    "    groups = eval(f.read())\n",
    "\n",
    "\n",
    "final_input = np.array(get_all_scores())\n",
    "somCol = 10\n",
    "somRow = 10\n",
    "som = som(final_input,12,4,somCol,somRow)\n",
    "ans =som.trainmodel()\n",
    "print ('trained model is',ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Result and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You may use markdown like this\n",
    "\n",
    "\n",
    "```python\n",
    "print \"Hello World\"\n",
    "```\n",
    "\n",
    "## You may use LaTeX equation like this\n",
    "\n",
    "$$e^x=\\sum_{i=0}^\\infty \\frac{1}{i!}x^i$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You may use table as html like this\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <td> row head 1 \n",
    "            <td> row head 2\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td> row body 1\n",
    "            <td> row body 2\n",
    "        </tr>   \n",
    "    </tbody>    \n",
    "</table>\n",
    "\n",
    "## You may insert photo like this\n",
    "\n",
    "<img src=\"./images/test.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] http://liu.cs.uic.edu/download/data/\n",
    "\n",
    "[2] https://www.cs.uic.edu/~liub/publications/WWW-2012-group-spam-camera-final.pdf\n",
    "\n",
    "[3] https://www.hindawi.com/journals/mpe/2016/4935792/\n",
    "\n",
    "[4] https://www.cs.uic.edu/~liub/FBS/fake-reviews.html\n",
    "\n",
    "[5]http://cs231n.github.io/neural-networks-1/\n",
    "\n",
    "[6]http://www.bbc.com/news/technology-22166606\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# {delete before submission} Proposal -- You may need to refer to this paragraph\n",
    "\n",
    "Prior works on opinion spam focused on detecting fake reviews and individual fake reviewers. However, a fake reviewer group (a group of reviewers who work collaboratively to write fake reviews) is even more damaging as they can take total control of the sentiment on the target product due to its size. Therefore, we are going to follow our base paper trying to identify fake reviews by clustering fake spammers into groups, which are also called group spammers[1]. Group spamming refers to a group of reviewers writing fake reviews together to promote or to demote some target products. The base paper[1] we choose has done experiments that show it is hard to detect spammer groups using review content features or even indicators for detecting abnormal behaviors of individual spammers because a group has more manpower to post reviews and thus, each member may no longer appear to behave abnormally. A group of reviewers refers to a set of reviewer-ids. The actual reviewers behind the ids could be a single person with multiple ids (sockpuppet), multiple persons, or a combination of both.\n",
    "\n",
    "\n",
    "Therefore, we will also implement a relation-based model “GSRank” described in [2] using an Artificial Neural Network [5] as the following figure1. The GS rank algorithm is an unsupervised iterative algorithm that works differently from the traditional supervised learning approach to spam detection. The paper [2] has concluded after experiments that “GSRank” performs better than the state-of-the-art supervised classification, regression, and learning to rank algorithms. Basically, we also follow this paper [2] to build a more effective model which can consider the inter-relationship among products, groups, and group members in computing group spamicity. In other words, we will try to reimplement the paper from scratch. In conclusion, after getting two different result as we mentioned above, we will evaluate with Precision, Recall and NDCG.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# {delete before submission}  Requirement\n",
    "\n",
    "\n",
    "\n",
    "Your main deliverable is your project notebook. This will act as both a written report plus a walkthrough of your code. This is the critical piece that will document and detail your project experience. We expect your project notebook to tell us the story of your project -- from initial question and data collection, to initial exploratory data analysis, perhaps to a revised question, to analyses, visualizations, and key takeaways.\n",
    "\n",
    "\n",
    "Note that we do not want to see a completely raw, moment-by-moment accounting of your project (include all 99 missteps and dead-ends); rather, you should carefully put together your final project notebook for submission that captures the key steps along the way.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cs670]",
   "language": "python",
   "name": "conda-env-cs670-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
